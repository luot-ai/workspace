# 点

1. transpose怎么算的，看<https://blog.csdn.net/wjc852456/article/details/110734751，>
   1. 一共三种方式，本篇用的是backward-stencil，注意交叠计算的时候的stride指的是EM
      1. 每个像素搞一个kernel，output交叠计算
   2. 另外两种方式也可以轻易找到不足之处，当然也可以针对他们进行优化
2. 本文提到的`多面体模型`在back-sten中是不适用的，因为计算不均匀（例子很好理解，自己画一画）
   1. ifmap纵向移动是+1.kernel则是-S
   2. `dependence-distance`也还不太懂
3. 架构
   1. 行数=kernel个数，kernel延横向广播
   2. 列数=ifmap列数，ifmap延纵向广播
   3. 输出是斜向和垂直都有
4. phase
   1. FLATTEN
      1. 先按channel来进行累加
      2. 假设一行5个元素，本来应该乘出来5个patch(3*3)，现在就映射成5个向量，每个向量9个元素
      3. 一个T处理一行ifmap，不同的T是ifmap的不同行
   2. ACCUM和TRANS
      1. 斜向的是`同一行ifmap不同列`重叠的累加
      2. 竖向的是`不同行同一列`重叠的累加（同一列对应同样的向量，只是`时刻`不同）
   3. 通过寄存器和输出路径达到流水化执行的效果
5. 最优化
   1. 在给定资源条件下，搭配下`缓存大小`和`访存策略`啥的，最小化`可能出现的最大载入延迟`
6. whatCanWeDo
   1. 他自个儿也提到了他是直接为不同的转置卷积层设定加速阵列，然后综合，并没有通用指令
   2. 说白了就是电路不通用，因为FSM是和卷积层的参数有关的
   3. 此外，这样也太占用资源了...它一个缓存好几Mb
   4. 咱们能不能做的通用一点，同时也适合于普通卷积层
      1. 能不能比他的资源少一点，但是提高程序员的可编程性，程序员可以根据板上资源进行编程
   5. 或者不用追求那么协调的重叠，牺牲一部分，但是提高灵活性
7. 实验
   1. 记得量化，ifmap-16bit，kernel-8bit
   2. Tcomp通常大于Tload说明计算密集，访存倒还好
      1. 可以牺牲复用性来？
   3. 【5，12，15，18，20】
      1. 【5，12】是离线转换成卷积来做，会受到步长S的影响**康康这个**
8. **6related**和**7futureWork**