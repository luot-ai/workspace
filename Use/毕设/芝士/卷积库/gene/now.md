
* 写文档，写论文
* 找到网络跑

  * 提示
    * 不行的层用im2col，哈哈哈
    * 条件k=3 偶数 尺寸最好小一点
  * 开干
    * 先在原框架上试一下【换wino5_normal】
    * 分别试下各层正确性
    * 最后把卷积换成自己的
  * 网络
    * tiny-darknet darkent这两个都满足，但不够主流？
    * yolo-tiny yolo 比较大
    * vgg 更大了
  * 验证
    * 确保有扩展指令执行
    * 功能验证-检测或者分类
    * 加速效果
  * lenet就算了，没有cfg，而且k=5不会改
    * 那篇文章倒是给了个改好的，不过感觉麻烦
* 性能调优

  * hard
    * 增加一些寄存器进行细致的访存-计算调优，因为ld_output实在太慢【这个不急，因为现在也有加速效果】
    * 简单改成oacc 0和3都就绪后续迭代就load的话应该会好些？因为等ld_output太慢了
  * easy
    * 调参-发射宽度
    * 调编译选项，改为O2
* 隐患

  * branch_mispredict
  * notrdySn可能有小问题，主要是squash对ldk的影响
* 小调整

  * debugflag，custom的打印信息
  * 写的丑的地方模板化
  * notrdylist和notrdyldk有歧义
  * 目前notrdyldk基本能维护只有至多一个inst在list里，所以pop_front和push_back用得有些不对也无所谓，但有机会还是得改改吧【换个数据结构】
  * 设置vloaddestvec=idx1
  * 前提太多了，若无必要勿增实体
* 后续

  * 目前一个最大的问题就是控制逻辑【精细调控vs改为通用方法直接调参】

    * 寄存器的数量，怎么样是最合适的，这里主要讲的是对性能的影响【啥时候置为“可取数”对性能有影响】
    * 寄存器数量改了，控制逻辑也改，有没有通用的方法，像重命名那样;通用的话可能方便设计空间探索
    * 感觉后期得大改，像重命名那样或者什么方法，目前就先这样
    * 感觉能做到数据流的唤醒方式?
  * 如何把问题迁移到darknet上，darknet是一款轻量级神经网络，适合部署在边缘端，但该框架没有winograd
  * 可能做算法上的探索：winograd和im2col如何搭配+一些扩展指令的点
