
* 调整奇怪的表格啥的
* 然后可能通读一下，才能捋顺改的那两段
* 莫名奇妙

  * CNNs 和 CNN 是一类问题，他前面也有标黄的部分：先放
  * PPVCU->PVCU?
* 修改：

  * 这一段感觉他理解错了，他ASIC引用的是通用加速里的第一类，通用引用的是第二类；我把他ASIC引用的改成ASIC本身的，然后其实说法也不太错，就先这样Accelerators for Convolutional Neural Networks (CNNs) can generally be categorized into two primary technical routes. The first approach involves designing Application-Specific Integrated Circuits (ASICs)cite{hegde2018morph,zhang2016cambricon} tailored specifically for CNN tasks. These ASICs often function as external co-processors to the host system, providing enhanced computational efficiency and speed by executing CNN operations in parallel, thereby offloading work from the main processorcite{yangweike2018base,dousiyuan2023,ning2020RECO,liao2021special}. The second approach leverages general-purpose processors by extending instruction sets and incorporating specialized hardware. This method allows for tightly coupled acceleration, enabling the processors to efficiently handle workloads while retaining their general-purpose functionality~\cite{9802445,8855445,10420491}.
  * 参考文献基本是直接在文章里 加\emph{et~al.}    会议期刊统一不用缩写
* 遗留

  * 感觉maxpooling还是有点问题

原来文章里的引用是这样

\begin{thebibliography}{1}
\bibliographystyle{IEEEtran}

\bibitem{raina2009large}
R.~Raina, A.~Madhavan, and A.~Y. Ng, ``Large-scale deep unsupervised learning using graphics processors,'' in \emph{Proceedings of the 26th annual international conference on machine learning}, 2009, pp. 873--880.

\bibitem{owens2008gpu}
J.~D. Owens, M.~Houston, D.~Luebke \emph{et~al.}, ``Gpu computing,'' \emph{Proceedings of the IEEE}, vol.~96, no.~5, pp. 879--899, 2008.

\bibitem{jouppi2017datacenter}
N.~P. Jouppi, C.~Young, N.~Patil \emph{et~al.}, ``In-datacenter performance analysis of a tensor processing unit,'' in \emph{Proceedings of the 44th annual international symposium on computer architecture}, 2017, pp. 1--12.

\bibitem{jouppi2023tpu}
N.~Jouppi, G.~Kurian, S.~Li, P.~Ma, R.~Nagarajan, L.~Nai, N.~Patil, S.~Subramanian, A.~Swing, B.~Towles \emph{et~al.}, ``Tpu v4: An optically reconfigurable supercomputer for machine learning with hardware support for embeddings,'' in \emph{Proceedings of the 50th Annual International Symposium on Computer Architecture}, 2023, pp. 1--14.

\bibitem{hegde2018morph}
K.~Hegde, R.~Agrawal, Y.~Yao, and C.~W. Fletcher, ``Morph: Flexible acceleration for 3d cnn-based video understanding,'' in \emph{2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 933--946.

\bibitem{zhang2016cambricon}
S.~Zhang, Z.~Du, L.~Zhang, H.~Lan, S.~Liu, L.~Li, Q.~Guo, T.~Chen, and Y.~Chen, ``Cambricon-x: An accelerator for sparse neural networks,'' in \emph{2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2016, pp. 1--12.

\bibitem{9802445}
X.~Yu, Z.~Yang, L.~Peng, B.~Lin, W.~Yang, and L.~Wang, ``Cnn specific isa extensions based on risc-v processors,'' in \emph{2022 5th International Conference on Circuits, Systems and Simulation (ICCSS)}, 2022, pp. 116--120.

\bibitem{8855445}
Z.~Li, W.~Hu, and S.~Chen, ``Design and implementation of cnn custom processor based on risc-v architecture,'' in \emph{2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 2019, pp. 1945--1950.

\bibitem{10420491}
S.~Wang, X.~Wang, Z.~Xu, B.~Chen, C.~Feng, Q.~Wang, and T.~T. Ye, ``Optimizing cnn computation using risc-v custom instruction sets for edge platforms,'' \emph{IEEE Transactions on Computers}, vol.~73, no.~5, pp. 1371--1384, 2024.

\bibitem{he2017mask}
K.~He, G.~Gkioxari, P.~Doll{\'a}r, and R.~Girshick, ``Mask r-cnn,'' in \emph{Proceedings of the IEEE international conference on computer vision}, 2017, pp. 2961--2969.

\bibitem{heckbert1995fourier}
P.~Heckbert, ``Fourier transforms and the fast fourier transform (fft) algorithm,'' \emph{Computer Graphics}, vol.~2, no. 1995, pp. 15--463, 1995.

\bibitem{dukhan2019indirect}
M.~Dukhan, ``The indirect convolution algorithm,'' \emph{arXiv preprint arXiv:1907.02129}, 2019.

\bibitem{Lavin_2016_CVPR}
A.~Lavin and S.~Gray, ``Fast algorithms for convolutional neural networks,'' in \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, June 2016.

\bibitem{fpga1}
S.~I. Venieris and C.-S. Bouganis, ``fpgaconvnet: A framework for mapping convolutional neural networks on fpgas,'' in \emph{2016 IEEE 24th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)}, 2016, pp. 40--47.

\bibitem{fpga2}
L.~Bai, Y.~Zhao, and X.~Huang, ``A cnn accelerator on fpga using depthwise separable convolution,'' \emph{IEEE Transactions on Circuits and Systems II: Express Briefs}, vol.~65, no.~10, pp. 1415--1419, 2018.

\bibitem{wang2019benchmarking}
Y.~E. Wang, G.-Y. Wei, and D.~Brooks, ``Benchmarking tpu, gpu, and cpu platforms for deep learning,'' \emph{arXiv preprint arXiv:1907.10701}, 2019.

\bibitem{waterman2014risc}
A.~Waterman, Y.~Lee, D.~A. Patterson, and K.~Asanovic, ``The risc-v instruction set manual, volume i: User-level isa, version 2.0,'' \emph{EECS Department, University of California, Berkeley, Tech. Rep. UCB/EECS-2014-54}, p.~4, 2014.

\bibitem{tehrani2019classification}
E.~Tehrani, T.~Graba, A.~S. Merabet, S.~Guilley, and J.-L. Danger, ``Classification of lightweight block ciphers for specific processor accelerated implementations,'' in \emph{2019 26th IEEE International Conference on Electronics, Circuits and Systems (ICECS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 747--750.

\bibitem{koppelmann2019risc}
B.~Koppelmann, P.~Adelt, W.~Mueller, and C.~Scheytt, ``Risc-v extensions for bit manipulation instructions,'' in \emph{2019 29th International Symposium on Power and Timing Modeling, Optimization and Simulation (PATMOS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 41--48.

\bibitem{amor2021risc}
H.~B. Amor, C.~Bernier, and Z.~P{\v{r}}ikryl, ``A risc-v isa extension for ultra-low power iot wireless signal processing,'' \emph{IEEE Transactions on Computers}, vol.~71, no.~4, pp. 766--778, 2021.

\bibitem{gautschi2017near}
M.~Gautschi, P.~D. Schiavone, A.~Traber, I.~Loi, A.~Pullini, D.~Rossi, E.~Flamand, F.~K. G{\"u}rkaynak, and L.~Benini, ``Near-threshold risc-v core with dsp extensions for scalable iot endpoint devices,'' \emph{IEEE transactions on very large scale integration (VLSI) systems}, vol.~25, no.~10, pp. 2700--2713, 2017.

\bibitem{qin2023roma}
S.~Qin, W.~Li, Z.~Fan, Z.~Wang, T.~Liu, H.~Wu, K.~Zhang, X.~An, X.~Ye, and D.~Fan, ``Roma: A reconfigurable on-chip memory architecture for multi-core accelerators,'' in \emph{2023 IEEE International Conference on High Performance Computing \& Communications, Data Science \& Systems, Smart City \& Dependability in Sensor, Cloud \& Big Data Systems \& Application (HPCC/DSS/SmartCity/DependSys)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 49--57.

\bibitem{tang2022gpgcn}
W.~Tang and P.~Zhang, ``Gpgcn: A general-purpose graph convolution neural network accelerator based on risc-v isa extension,'' \emph{Electronics}, vol.~11, no.~22, p. 3833, 2022.

\bibitem{lee2021risc}
S.-Y. Lee, Y.-W. Hung, Y.-T. Chang, C.-C. Lin, and G.-S. Shieh, ``Risc-v cnn coprocessor for real-time epilepsy detection in wearable application,'' \emph{IEEE transactions on biomedical circuits and systems}, vol.~15, no.~4, pp. 679--691, 2021.

\bibitem{garofalo2020xpulpnn}
A.~Garofalo, G.~Tagliavini, F.~Conti, D.~Rossi, and L.~Benini, ``Xpulpnn: accelerating quantized neural networks on risc-v processors through isa extensions. in 2020 design, automation \& test in europe conference \& exhibition (date),'' 2020.

\bibitem{kabylkas2021effective}
N.~Kabylkas, T.~Thorn, S.~Srinath, P.~Xekalakis, and J.~Renau, ``Effective processor verification with logic fuzzer enhanced co-simulation,'' in \emph{MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture}, 2021, pp. 667--678.

\bibitem{9406333}
A.~Garofalo, G.~Tagliavini, F.~Conti, L.~Benini, and D.~Rossi, ``Xpulpnn: Enabling energy efficient and flexible inference of quantized neural networks on risc-v based iot end nodes,'' \emph{IEEE Transactions on Emerging Topics in Computing}, vol.~9, no.~3, pp. 1489--1505, 2021.

\bibitem{9082159}
H.~Jia, H.~Valavi, Y.~Tang, J.~Zhang, and N.~Verma, ``A programmable heterogeneous microprocessor based on bit-scalable in-memory computing,'' \emph{IEEE Journal of Solid-State Circuits}, vol.~55, no.~9, pp. 2609--2621, 2020.

\bibitem{DBLP:journals/corr/abs-1811-04047}
H.~Jia, Y.~Tang, H.~Valavi, J.~Zhang, and N.~Verma, ``A microprocessor implemented in 65nm {CMOS} with configurable and bit-scalable accelerator for programmable in-memory computing,'' \emph{CoRR}, vol. abs/1811.04047, 2018. [Online]. Available: \url{http://arxiv.org/abs/1811.04047}

\bibitem{yangweike2018base}
H.~Yang and JING, ``Design and implementation of cnn acceleration module based on rocket-chip open source processor,'' \emph{Microelectronics and Computer}, vol.~35, no.~4, 2018.

\bibitem{dousiyuan2023}
D.~Siyuan, ``Design and simulation studies of convolutional neural network accelerator based on risc-v,'' Master's thesis, University of Electronic Science and Technology of China, 2023.

\bibitem{ning2020RECO}
L.~Z. F.~Z. Ning~Wu, Tao~Jiang and F.~Ge, ``A reconﬁgurable convolutional neural network-accelerated coprocessor based on risc-v instruction set,'' \emph{Electronics}, vol.~9, no.~6, p. 1005, 2020.

\bibitem{liao2021special}
W.~Z.~H. LIAO H~S and L.~B, ``Special instruction set processor for convolutional neural network based on risc-v,'' \emph{Computer Engineering}, vol.~47, no.~7, pp. 196--204, 2021.

\bibitem{sima2000design}
D.~Sima, ``The design space of register renaming techniques,'' \emph{IEEE micro}, vol.~20, no.~5, pp. 70--83, 2000.

\bibitem{rawat2018associative}
P.~S. Rawat, A.~Sukumaran-Rajam, A.~Rountev, F.~Rastello, L.-N. Pouchet, and P.~Sadayappan, ``Associative instruction reordering to alleviate register pressure,'' in \emph{SC18: International Conference for High Performance Computing, Networking, Storage and Analysis}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 590--602.

\bibitem{redmon2016you}
J.~Redmon, S.~Divvala, R.~Girshick, and A.~Farhadi, ``You only look once: Unified, real-time object detection,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2016, pp. 779--788.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image recognition,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2016, pp. 770--778.

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for large-scale image recognition,'' \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{lecun1998gradient}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner, ``Gradient-based learning applied to document recognition,'' \emph{Proceedings of the IEEE}, vol.~86, no.~11, pp. 2278--2324, 1998.
