大创

1. 动机：虽然视频去模糊与文段的检测识别算法在最近是比较热门的领域，但是针对视频中文字去模糊的算法却几乎没有
2. 场景：短视频平台 -  无人驾驶 - 车辆监控
3. 原因：视频拍摄设备不稳定 - 高速移动
4. 一些经典的OCR算法可能难以实现文本的识别任务，甚至是文本位置的检测都可能成为问题
5. 架构：文本检测 文本追踪 去模糊+文字识别
   1. 是目标检测(Object Detection)领域的一个子问题
      1. 改了部分的网络结构
   2. 目标追踪问题，比较经典的算法有SORT算法，它是基于目标检测算法的一个追踪算法
   3. 一般的思路是   先去模糊，再进行文本识别
   4. 对文本框图去模糊并识别。在这一步流程中，我们调整融合了 `视频去模糊网络`和 `文本识别网络`，将后者 `特征提取的部分`更换成整合后的视频去模糊网络中 `特征提取、对齐与融合`的模块。经实验验证，将去模糊部分隐式地嵌入识别网络中
      1. 文字识别包括
         1. 一个用于特征提取的视觉模型vision model和一个用于文本转录的序列模型sequence model
6. 当时使用EDVR模型，其他的还有VRT/MPRNet等等
   1. EDVR是视频重建模型，给中间帧作为参考帧，用它周围的帧恢复它的质量
   2. 先各帧去模糊
   3. 然后PCD对齐
      1. 可形变卷积，更好地进行像素对齐
   4. 然后TSA融合不同帧图像信息
      1. 引入了注意力机制，时间和空间通道上赋权重
   5. 融合特征再进行重建
7. 数据集
   1. 有模糊视频，也有模糊文字图片
   2. 但是我们需要的是模糊文字的视频
   3. 我们的做法是
      1. DeBlurGan中提出了一种基于马尔科夫随机过程生成随机轨迹进而生成对应的模糊滤波器的方法
      2. 基于该方法，并随机调整轨迹的最大长度，以此长度作为文本图像清晰度的指标（从0到71以此增大）
