我们架构组正在探索如何结合当前热门的大模型应用，对未来芯片架构进行优化设计。
我们的芯片已经发展到第四代，每一代都会引入新的特性和改进。
团队会通过系统仿真来验证这些架构优化的可行性和实际性能表现。如果你加入，将会参与这类仿真和性能评估的工作。

之前我们这边也有同学研究过 GPGPU 相关的方向，但目前他们的实现好像只支持到 NVIDIA V100。
而之后的新一代 GPU，比如 B 系列（如 A100、B100 等） 目前还不支持，包括最新的 H100 也没有适配。
所以如果要继续往下推进这块工作，后续还需要补充和适配的内容会比较多。
此外，关于 GM5，最近的更新也比较频繁，需要及时跟进。

我们组这边其实也有做算法的同学，所以未来你这边可能会和他们有一定的配合。
你现在也在使用编程辅助工具（比如 Copilot），其实这也反映了现在 AI 工具在开发中的作用越来越大。
基于这种趋势，我们也希望开发属于我们自己的辅助开发工具，比如：
针对内部已有的软件栈；
自动生成某些 算子（Operators）；
在写代码时提供智能提示或生成；
甚至将来可能可以辅助生成 RTL 代码。
总的来说，就是希望搭建一套自研的 AI 辅助开发系统，实现从算法、代码到 RTL 的半自动化支持。

我们的工作既包括底层的架构探索，也包括从上层大模型应用出发，反向驱动架构优化。
通过分析 LLM、Diffusion 等复杂模型的整体 workload，而非单算子，
提炼其对硬件在存储、调度、ISA 等方面的需求，再反馈到架构设计中，以期相较竞品实现性能优势。
整个过程涉及从模型、框架、编译器、runtime 到底层 RTL/ISA 的全栈优化，
目标是在不同模型配置（如 size、batch、seq_len）下达到系统级的最优设计平衡（trade-off）

我们团队目前的芯片架构设计已经发展到第六代，每一代设计都有明确的目标与时间窗口，而探索性的工作则更关注为未来几代架构奠定基础。
类似 Wi-Fi 的标准演进，芯片架构拥有自身的路线图，持续迭代，与上层应用的需求密切关联。
架构的演进是一个没有终点的过程，持续推动性能优化与系统设计的升级，除非遇到工艺或物理层面的极限。
